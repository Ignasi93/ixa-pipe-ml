{
  "name": "IXA pipes",
  "tagline": "Ready to Use NLP tools",
  "body": "\r\nixa-pipe-ml\r\n=============\r\n\r\nixa-pipe-ml is the Machine Learning Component of IXA pipes. ixa-pipe-ml allows to\r\ntrain and evaluate the models for every IXA-pipe available.\r\n**Current version is 0.0.1**\r\n\r\nixa-pipe-ml is part of IXA pipes, a multilingual set of NLP tools developed\r\nby the IXA NLP Group [http://ixa2.si.ehu.es/ixa-pipes].\r\n\r\nPlease go to [http://ixa2.si.ehu.es/ixa-pipes] for general information about the IXA\r\npipes tools but also for **official releases, including source code and binary\r\npackages for all the tools in the IXA pipes toolkit**.\r\n\r\nThis document is intended to be the **usage guide of ixa-pipe-ml**. If you really need to clone\r\nand install this repository instead of using the releases provided in\r\n[http://ixa2.si.ehu.es/ixa-pipes], please scroll down to the end of the document for\r\nthe [installation instructions](#installation).\r\n\r\n**NOTICE!!**: ixa-pipe-ml is now in [Maven Central](http://search.maven.org/)\r\nfor easy access to its API.\r\n\r\n## TABLE OF CONTENTS\r\n\r\n1. [Overview of ixa-pipe-ml](#overview)\r\n  + [Available features](#features)\r\n  + [NERC distributed models](#nerc-models)\r\n  + [OTE distributed models](#ote-models)\r\n2. [Usage of ixa-pipe-ml](#cli-usage)\r\n  + [NERC tagging](#tagging)\r\n  + [Opinion Target Extraction (OTE)](#ote)\r\n  + [Server mode](#server)\r\n  + [Training your own models](#training)\r\n  + [Evaluation](#evaluation)\r\n3. [API via Maven Dependency](#api)\r\n4. [Git installation](#installation)\r\n\r\n## OVERVIEW\r\n\r\nixa-pipe-ml provides:\r\n\r\n+ **NERC** for Basque, English, Spanish, Dutch, German and Italian. The named entity types are based on:\r\n   + **CONLL**: LOCATION, MISC, ORGANIZATION and PERSON. See [CoNLL 2002](http://www.clips.ua.ac.be/conll2002/ner/) and [CoNLL 2003](http://www.clips.ua.ac.be/conll2003/ner/) for more information.\r\n   + **SONAR-1**: for Dutch, six main types, including CoNLL types plus PRODUCT and EVENT.\r\n   + **Ancora**: for Spanish, six main types, including CoNLL types plus DATE and NUMBER.\r\n+ **Opinion Target Extraction** (OTE) for English. The models are trained on the SemEval 2014 and 2015 datasets;\r\n  **ixa-pipe-ml was the best system** in [SemEval 2015 OTE subtask within task 12](http://alt.qcri.org/semeval2015/task12/).\r\n+ **SuperSense Tagging** (SST) for English. The models are trained on Semcor.\r\n\r\nEvery model is self-contained, that is, the prop files are not needed to use them.\r\nYou will find for each model a properties file describing its training although it is\r\nnot needed to run the model. Please see the traininParams.properties template file\r\nfor all available training options and documentation.\r\n\r\nWe provide competitive models based on robust local features and exploiting unlabeled data\r\nvia clustering features. The clustering features are based on Brown, Clark (2003)\r\nand Word2Vec clustering plus some gazetteers in some cases.\r\nTo avoid duplication of efforts, we use and contribute to the API provided by the\r\n[Apache OpenNLP project](http://opennlp.apache.org) with our own custom developed features for each of the three tasks.\r\n\r\n### Features\r\n\r\n**A description of every feature is provided in the trainParams.properties properties\r\nfile** distributed with ixa-pipe-ml. As the training functionality is configured in\r\nproperties files, please do check this document. For each model distributed,\r\nthere is a prop file which describes the training of the model, as well as a\r\nlog file which provides details about the evaluation and training process.\r\n\r\n### NERC-Models\r\n\r\nEvery result in reported here can be reproduced using the evaluation functionality of ixa-pipe-ml or\r\nwith the [conlleval script](http://www.cnts.ua.ac.be/conll2002/ner/bin/conlleval.txt) using these scripts:\r\n\r\n**Reproducing results with conlleval**: [conlleval-results](http://ixa2.si.ehu.es/ixa-pipes/models/results-conlleval.tar.gz)\r\n\r\n**NERC models**:\r\n\r\n  + **Release 1.5.4** [685MB]: [nerc-models-latest.tgz](http://ixa2.si.ehu.es/ixa-pipes/models/nerc-models-1.5.4.tgz)\r\n\r\nEvery model is trained with the averaged Perceptron algorithm as described in (Collins 2002) and as implemented\r\nin Apache OpenNLP.\r\n\r\n+ **Basque**: eu-clusters model, trained on egunkaria dataset, F1 76.72 on 3 class evaluation and F1 75.40 on 4 classes.\r\n\r\n+ **English Models**:\r\n\r\n  + **CoNLL 2003 models**: We distribute models trained with local features\r\n  and with external knowledge. Each of the models improve in F1 (reported on testb data)\r\n  but they get somewhat slower:\r\n    + CoNLL 2003 local + brown features: F1 88.50\r\n    + CoNLL 2003 local + clark features: F1 88.97\r\n    + CoNLL 2003 light clusters model: F1 90.27\r\n    + CoNLL 2003 clusters model: F1 90.82\r\n    + CoNLL 2003 clusters + dicts: F1 91.19\r\n\r\n  + **Combined models**: trained using Ontonotes 4.0, conll03 and muc 7 data, good for out of domain usage.\r\n\r\n+ **Spanish Models**:\r\n\r\n  + CoNLL 2002 clusters: F1 84.16\r\n  + CoNLL 2002 clusters + dict: F1 84.30\r\n\r\n+ **Dutch Models**:\r\n  + CoNLL 2002 clusters: F1 84.23\r\n  + CoNLL 2002 clusters + dict: F1 84.91\r\n\r\n+ **German Models**:\r\n  + CoNLL 2003 clusters + dict: F1 76.42\r\n\r\n+ **Italian Models**:\r\n  + Evalita09 clusters: F1 80.38\r\n\r\n### OTE-Models\r\n\r\n+ **Latest models**: [ote-models-latest](http://ixa2.si.ehu.es/ixa-pipes/models/ote-models-1.5.0.tgz)\r\n\r\n+ **English Models**:\r\n    + Trained on SemEval 2014 restaurants dataset.\r\n    + Trained on SemEval 2015 restaurants dataset (ote subtask winner).\r\n\r\n## CLI-USAGE\r\n\r\nixa-pipe-ml provides the following command-line basic functionalities:\r\n\r\n1. **server**: starts a TCP service loading the model and required resources.\r\n2. **client**: sends a NAF document to a running TCP server.\r\n2. **tag**: reads a NAF document containing *wf* and *term* elements and tags named\r\n   entities.\r\n2. **ote**: reads a NAF document containing *wf* and *term* elements and performs\r\n   opinion target extraction (OTE).\r\n3. **train**: trains new models for NERC, OTE and SST with several options\r\n   available.\r\n4. **eval**: evaluates a trained model with a given test set.\r\n5. **cross**: it performs cross validation on a corpus.\r\n\r\nEach of these functionalities are accessible by adding (server|client|tag|ote|train|eval|cross) as a\r\nsubcommand to ixa-pipe-ml-$version.jar. Please read below and check the -help\r\nparameter:\r\n\r\n````shell\r\njava -jar target/ixa-pipe-ml-$version.jar (tag|ote|train|eval|cross) -help\r\n````\r\n**Every option for training is documented in the trainParams.properties file distributed with\r\nixa-pipe-ml**. Please do read that file!!\r\n\r\n### Tagging\r\n\r\nIf you are in hurry, just execute:\r\n\r\n````shell\r\ncat file.txt | ixa-pipe-tok | ixa-pipe-pos | java -jar $PATH/target/ixa-pipe-ml-$version.jar tag -m model.bin\r\n````\r\n\r\nIf you want to know more, please follow reading.\r\n\r\nixa-pipe-ml reads NAF documents (with *wf* and *term* elements) via standard input and outputs NAF\r\nthrough standard output. The NAF format specification is here:\r\n\r\n(http://wordpress.let.vupr.nl/naf/)\r\n\r\nYou can get the necessary input for ixa-pipe-ml by piping\r\n[ixa-pipe-tok](https://github.com/ixa-ehu/ixa-pipe-tok) and\r\n[ixa-pipe-pos](https://github.com/ixa-ehu/ixa-pipe-pos) as shown in the\r\nexample.\r\n\r\nThere are several options to tag with ixa-pipe-ml:\r\n\r\n+ **model**: pass the model as a parameter.\r\n+ **language**: pass the language as a parameter.\r\n+ **outputFormat**: Output annotation in a format: available CoNLL03, CoNLL02,\r\n  OpenNLP native format and NAF. It defaults to NAF.\r\n+ **lexer**: switches on the rule-based DFA for NERC tagging. Currently we only provide\r\n  one option **numeric**, which identifies \"numeric entities\" such as DATE,\r\n  TIME, MONEY and PERCENT for all the languages currently in ixa-pipe-ml.\r\n+ **dictTag**: directly tag named entities contained in a gazetteer.\r\n  + **tag**: with tag option, only dictionary entities are annotated.\r\n  + **post**: with post option, the output of the statistical model is\r\n    post-processed.\r\n+ **dictPath**: the directory containing the gazetteers for the --dictTag\r\n  option.\r\n\r\n**Example**:\r\n\r\n````shell\r\ncat file.txt | ixa-pipe-tok | ixa-pipe-pos | java -jar $PATH/target/ixa-pipe-ml-$version.jar tag -m nerc-models-$version/en/en-local-conll03.bin\r\n````\r\n### OTE\r\n\r\nAs for NER tagging, the ote requires an input NAF with *wf* and *term* elements:\r\n\r\n````shell\r\ncat file.txt | ixa-pipe-tok | ixa-pipe-pos | java -jar $PATH/target/ixa-pipe-ml-$version.jar ote -m model.bin\r\n````\r\n\r\nixa-pipe-ml reads NAF documents (with *wf* and *term* elements) via standard input and outputs opinion targets in NAF\r\nthrough standard output. The NAF format specification is here:\r\n\r\n(http://wordpress.let.vupr.nl/naf/)\r\n\r\nYou can get the necessary input for ixa-pipe-ml by piping\r\n[ixa-pipe-tok](https://github.com/ixa-ehu/ixa-pipe-tok) and\r\n[ixa-pipe-pos](https://github.com/ixa-ehu/ixa-pipe-pos) as shown in the\r\nexample.\r\n\r\nThere are several options to tag with ixa-pipe-ml:\r\n\r\n+ **model**: pass the model as a parameter.\r\n+ **language**: pass the language as a parameter.\r\n+ **outputFormat**: Output annotation in a format: available OpenNLP native format and NAF. It defaults to NAF.\r\n\r\n**Example**:\r\n\r\n````shell\r\ncat file.txt | ixa-pipe-tok | ixa-pipe-pos | java -jar $PATH/target/ixa-pipe-ml-$version.jar ote -m ote-models-$version/en/ote-semeval2014-restaurants.bin\r\n````\r\n\r\n### Server\r\n\r\nWe can start the TCP server as follows:\r\n\r\n````shell\r\njava -jar target/ixa-pipe-ml-$version.jar server -l en --port 2060 -m en-91-18-conll03.bin\r\n````\r\nOnce the server is running we can send NAF documents containing (at least) the term layer like this:\r\n\r\n````shell\r\n cat file.pos.naf | java -jar target/ixa-pipe-ml-$version.jar client -p 2060\r\n````\r\n\r\n### Training\r\n\r\nTo train a new model for NERC, OTE or SST, you just need to pass a training parameters file as an\r\nargument. As it has been already said, the options are documented in the\r\ntemplate trainParams.properties file.\r\n\r\n**Example**:\r\n\r\n````shell\r\njava -jar target/ixa.pipe.nerc-$version.jar train -p trainParams.properties\r\n````\r\n**Training with Features using External Resources**: For training with dictionary or clustering\r\nbased features (Brown, Clark and Word2Vec) you need to pass the lexicon as\r\nvalue of the respective feature in the prop file. This is only for training, as\r\nfor tagging or evaluation the model is serialized with all resources included.\r\n\r\n### Evaluation\r\n\r\nYou can evaluate a trained model or a prediction data against a reference data\r\nor testset.\r\n\r\n+ **language**: provide the language.\r\n+ **model**: if evaluating a model, pass the model.\r\n+ **testset**: the testset or reference set.\r\n+ **corpusFormat**: the format of the reference set and of the prediction set\r\n  if --prediction option is chosen.\r\n+ **prediction**: evaluate against a  prediction corpus instead of against a\r\n  model.\r\n+ **evalReport**: detail of the evaluation report\r\n  + **brief**: just the F1, precision and recall scores\r\n  + **detailed**, the F1, precision and recall per class\r\n  + **error**: the list of false positives and negatives\r\n\r\n**Example**:\r\n\r\n````shell\r\njava -jar target/ixa.pipe.nerc-$version.jar eval -m nerc-models-$version/en/en-local-conll03.bin -l en -t conll03.testb\r\n````\r\n\r\n## API\r\n\r\nThe easiest way to use ixa-pipe-ml programatically is via Apache Maven. Add\r\nthis dependency to your pom.xml:\r\n\r\n````shell\r\n<dependency>\r\n    <groupId>eus.ixa</groupId>\r\n    <artifactId>ixa-pipe-ml</artifactId>\r\n    <version>1.5.4</version>\r\n</dependency>\r\n````\r\n\r\n## JAVADOC\r\n\r\nThe javadoc of the module is located here:\r\n\r\n````shell\r\nixa-pipe-ml/target/ixa-pipe-ml-$version-javadoc.jar\r\n````\r\n\r\n## Module contents\r\n\r\nThe contents of the module are the following:\r\n\r\n    + formatter.xml           Apache OpenNLP code formatter for Eclipse SDK\r\n    + pom.xml                 maven pom file which deals with everything related to compilation and execution of the module\r\n    + src/                    java source code of the module and required resources\r\n    + Furthermore, the installation process, as described in the README.md, will generate another directory:\r\n    target/                 it contains binary executable and other directories\r\n    + trainParams.properties      A template properties file containing documention\r\n    for every available option\r\n\r\n\r\n## INSTALLATION\r\n\r\nInstalling the ixa-pipe-ml requires the following steps:\r\n\r\nIf you already have installed in your machine the Java 1.7+ and MAVEN 3, please go to step 3\r\ndirectly. Otherwise, follow these steps:\r\n\r\n### 1. Install JDK 1.7 or JDK 1.8\r\n\r\nIf you do not install JDK 1.7+ in a default location, you will probably need to configure the PATH in .bashrc or .bash_profile:\r\n\r\n````shell\r\nexport JAVA_HOME=/yourpath/local/java7\r\nexport PATH=${JAVA_HOME}/bin:${PATH}\r\n````\r\n\r\nIf you use tcsh you will need to specify it in your .login as follows:\r\n\r\n````shell\r\nsetenv JAVA_HOME /usr/java/java17\r\nsetenv PATH ${JAVA_HOME}/bin:${PATH}\r\n````\r\n\r\nIf you re-login into your shell and run the command\r\n\r\n````shell\r\njava -version\r\n````\r\n\r\nYou should now see that your JDK is 1.7 or 1.8.\r\n\r\n### 2. Install MAVEN 3\r\n\r\nDownload MAVEN 3 from\r\n\r\n````shell\r\nwget http://apache.rediris.es/maven/maven-3/3.0.5/binaries/apache-maven-3.0.5-bin.tar.gz\r\n````\r\nNow you need to configure the PATH. For Bash Shell:\r\n\r\n````shell\r\nexport MAVEN_HOME=/home/ragerri/local/apache-maven-3.0.5\r\nexport PATH=${MAVEN_HOME}/bin:${PATH}\r\n````\r\n\r\nFor tcsh shell:\r\n\r\n````shell\r\nsetenv MAVEN3_HOME ~/local/apache-maven-3.0.5\r\nsetenv PATH ${MAVEN3}/bin:{PATH}\r\n````\r\n\r\nIf you re-login into your shell and run the command\r\n\r\n````shell\r\nmvn -version\r\n````\r\n\r\nYou should see reference to the MAVEN version you have just installed plus the JDK that is using.\r\n\r\n### 3. Get module source code\r\n\r\nIf you must get the module source code from here do this:\r\n\r\n````shell\r\ngit clone https://github.com/ixa-ehu/ixa-pipe-ml\r\n````\r\n\r\n### 4. Compile\r\n\r\nExecute this command to compile ixa-pipe-ml:\r\n\r\n````shell\r\ncd ixa-pipe-ml\r\nmvn clean package\r\n````\r\nThis step will create a directory called target/ which contains various directories and files.\r\nMost importantly, there you will find the module executable:\r\n\r\nixa-pipe-ml-$version.jar\r\n\r\nThis executable contains every dependency the module needs, so it is completely portable as long\r\nas you have a JVM 1.7 installed.\r\n\r\nTo install the module in the local maven repository, usually located in ~/.m2/, execute:\r\n\r\n````shell\r\nmvn clean install\r\n````\r\n\r\n## Contact information\r\n\r\n````shell\r\nRodrigo Agerri\r\nIXA NLP Group\r\nUniversity of the Basque Country (UPV/EHU)\r\nE-20018 Donostia-San Sebastián\r\nrodrigo.agerri@ehu.eus\r\n````\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}